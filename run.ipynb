{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.10 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "bb8c43e82f35742f19efcdc7a7dc38b7799efd14d902f4c4233927ddd7226b44"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Returns a cleaned X and y dataset to be used for classification.\n",
    "\"\"\"\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "PATH=r\"C:\\Users\\Jeroen Gijsbers\\OneDrive - TU Eindhoven\\Uni\\Master\\Jaar 1\\Kwartiel 3\\2AMV10 - Visual Analytics\\Project\\2AMV10-group-16\"\n",
    "IMG_SIZE = 180\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \"\"\"\n",
    "        Reads the images and returns them as arrays X and y\n",
    "\n",
    "        returns: X      array containing np-array-representation of images\n",
    "                 y      array containing corresponding labels\n",
    "    \"\"\"\n",
    "    #print(os.curdir)\n",
    "    #os.chdir('../data/trainingData/TrainingImages')\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = []\n",
    "    sys.path.insert(0, PATH)\n",
    "    path = \"./data/trainingData/TrainingImages\"\n",
    "    i = 0\n",
    "    limit = 200\n",
    "    for label in [name for name in os.listdir(path) if os.path.isdir(f\"{path}/{name}\")]:\n",
    "        labels.append(label)\n",
    "        for image in [name for name in os.listdir(f\"{path}/{label}\")]:\n",
    "            #X.append(cv2.imread(f\"{path}/{label}/{image}\"))\n",
    "            try:\n",
    "                img = cv2.imread(f\"{path}/{label}/{image}\")\n",
    "                X.append(img)\n",
    "                y.append(label)\n",
    "                i+= 1\n",
    "            except:\n",
    "                print(\"something went wrong, probably .db file\")\n",
    "            if i == limit:\n",
    "                break\n",
    "        if i == limit:\n",
    "            break\n",
    "    return np.array(X), y, labels#.reshape(50, 256*256), y, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X, y \u001b[38;5;241m=\u001b[39m read_data()\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# X, y, labels = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "from random import randint\n",
    "import cv2\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self):\n",
    "        batch_size = 32\n",
    "        img_height = 180\n",
    "        img_width = 180\n",
    "\n",
    "    def predict(self, image):\n",
    "        \"\"\"\n",
    "            Takes an image, converts it to a np array, and uses the model to predict a label.\n",
    "\n",
    "            Returns:\n",
    "                pred    String      predicted label\n",
    "        \"\"\"\n",
    "        if not self.rf:\n",
    "            print(\"Please fit the model first.\")\n",
    "            return\n",
    "        test = cv2.imread(image, mode=\"RGB\")\n",
    "        return self.rf.predict(test)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "            Splits the data into a train and a test set.\n",
    "        \"\"\"\n",
    "        self.X, self.y, self.labels = read_data()\n",
    "        #enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        #self.X = enc.fit_transform(self.X, self.y)\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2)\n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(self.X_train, self.y_train, test_size=0.25)\n",
    "        print(f\"Shape of training image: {self.X_train[0].shape}\")\n",
    "\n",
    "    def show_images(self, grayscale=False, display_test=False):\n",
    "        \"\"\"\n",
    "            Shows 10 random images from the dataset\n",
    "        \"\"\"\n",
    "        def plot_images(X, y, grayscale=False, display_test=False):\n",
    "            fig, axes = plt.subplots(1, len(X), figsize=(15,30))\n",
    "            for n in range(len(X)):\n",
    "                if grayscale:\n",
    "                    axes[n].imshow(X[n], cmap='gray')\n",
    "                else:\n",
    "                    axes[n].imshow(X[n])\n",
    "                print(y[n])\n",
    "                print(np.argmax(y[n]))\n",
    "                print(self.labels[:5])\n",
    "                print(self.labels[np.argmin(y[n])])\n",
    "                axes[n].set_xlabel(self.labels[np.argmin(y[n])])\n",
    "                axes[n].set_xticks(()), axes[n].set_yticks(())\n",
    "            plt.show()\n",
    "\n",
    "        images = [randint(0,len(self.X_train)-1) for i in range(5)]\n",
    "        X_random = [self.X_train[i] for i in images]\n",
    "        y_random = [self.y_train[i] for i in images]\n",
    "        plot_images(X_random, y_random)\n",
    "\n",
    "        if display_test:\n",
    "            images = [randint(0,len(self.X_test)) for i in range(5)]\n",
    "            X_random = [self.X_test[i] for i in images]\n",
    "            y_random = [self.y_test[i] for i in images]\n",
    "            plot_images(X_random, y_random)\n",
    "\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "            Fits the model\n",
    "        \"\"\"\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(512, (3, 3), activation='relu',\n",
    "                                input_shape=IMG_SHAPE))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(256, (3, 3), activation='relu',\n",
    "                                input_shape=IMG_SHAPE))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.3))\n",
    "        model.add(layers.Flatten())\n",
    "        #model.add(layers.Dense(512, activation='relu'))\n",
    "        model.add(layers.Dense(len(self.labels), activation='sigmoid'))\n",
    "        rmsprop_optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=rmsprop_optimizer,\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        self.model = model\n",
    "\n",
    "    def evaluate(self, train=None, stop_training=False, generator=None):\n",
    "        learning_curves = {}\n",
    "        if train and not stop_training:\n",
    "            if generator:\n",
    "                # TODO: deploy generator\n",
    "                pass\n",
    "            else:\n",
    "                history = self.model.fit(\n",
    "                    self.X_train, self.y_train, epochs=3, batch_size=3,\n",
    "                    verbose=1, validation_data=(self.X_val, self.y_val))\n",
    "                learning_curves = history.history\n",
    "            # TODO: save to file\n",
    "        else:\n",
    "            # TODO: load from file\n",
    "            pass\n",
    "        lc = pd.DataFrame(learning_curves)\n",
    "        print(f\"Max val score: {lc.iloc[:,3].max()*100}%\")\n",
    "        lc.plot(lw=2, style=['b:', 'r:', 'b-', 'r-'])\n",
    "        plt.xlabel('epochs')\n",
    "        plt.show()\n",
    "\n",
    "        print(self.model.summary())\n",
    "        plot_model(self.model)\n",
    "\n",
    "                \n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "            Get accuracy scores based X_test and y_test\n",
    "            TODO implement\n",
    "        \"\"\"\n",
    "        if not self.X_test:\n",
    "            self.train()\n",
    "        xvals = cross_validate(self.rf, self.X, self.y, return_train_score=True, n_jobs=-1)\n",
    "        return xvals['train_score'], xvals['test_score']\n",
    "\n",
    "\n",
    "    def feature_importance(self, nr_images=10, nr_rows=2):\n",
    "        \"\"\"\n",
    "            Plot graphs with images and importances\n",
    "            for nr_images images on nr_rows rows\n",
    "\n",
    "            TODO implement\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(nr_images, nr_rows)\n",
    "        pass\n",
    "\n",
    "\n",
    "    def misclassifications(self):\n",
    "        \"\"\"\n",
    "            Plot items with their misinterpreted label\n",
    "        \"\"\"\n",
    "        y_pred = self.rf.predict(self.X_test)\n",
    "        misclassified = np.nonzero(y_pred != list(self.y_test))[0]\n",
    "\n",
    "    def save(self):\n",
    "        if not self.rf:\n",
    "            print(\"Unable to save model since it doesn't exist\")\n",
    "        joblib.dump(self.rf, \"./random_forest.joblib\", compress=3)\n",
    "\n",
    "    def load(self):\n",
    "        self.rf = joblib.load(\"./random_forest.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "model.load_data()\n",
    "model.build()"
   ]
  }
 ]
}